{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization using Memory Augmented Neural Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook and the accompanying paper <a href=\"http://arxiv.org/abs/1806.00044\">Text Normalization using Memory Augmented Neural Networks</a>  demonstrates an accuracy of 99.4% (English) and 99.3% (Russian) on the Text Normalization Challenge by Richard Sproat and Navdeep Jaitly. The approach used here has secured the 6th position in the [Kaggle Russian Text Normalization Challenge](https://www.kaggle.com/c/text-normalization-challenge-russian-language) by Google's Text Normalization Research Group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "---\n",
    "1. [Import Dependencies](#import)\n",
    "2. [Global Config](#config)\n",
    "3. [Load Dataset](#load)\n",
    "4. [XGBoost Classification](#xgb)\n",
    "5. [Encode Data](#encode)\n",
    "6. [DNC Normalization](#dnc)\n",
    "7. [Data Postprocessing](#post)\n",
    "8. [Results Analysis](#result)\n",
    "9. [Comparison](#comparison)  \n",
    "10. [Conclusion](#conclusion)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies\n",
    "<a id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metal_geek/anaconda3/envs/deep-tf/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils import Encoder\n",
    "from utils import Normalized2String\n",
    "from XGBclassify import XGB\n",
    "import DNCnormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**System Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 30 2018 \n",
      "\n",
      "CPython 3.6.3\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.13.3\n",
      "pandas 0.21.0\n",
      "matplotlib 2.1.0\n",
      "seaborn 0.8.1\n",
      "sklearn 0.19.1\n",
      "xgboost 0.6\n",
      "tensorflow 1.3.0\n",
      "\n",
      "compiler   : GCC 7.2.0\n",
      "system     : Linux\n",
      "release    : 4.13.0-1017-gcp\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,pandas,matplotlib,seaborn,sklearn,xgboost,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Config\n",
    "<a id=\"config\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language : English or Russian?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang = 'english'\n",
    "lang = 'russian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == 'english':\n",
    "    # input data\n",
    "    data_directory = '../data/english/'\n",
    "    data = data_directory+'output-00099-of-00100_processed.csv'\n",
    "    vocab = data_directory+'en_vocab.data'\n",
    "    # interim data\n",
    "    encoded_file = data_directory+'en_encoded.npy'\n",
    "    encoded_len_file = data_directory+'en_encoded_len.npy'\n",
    "    normalized_file = data_directory+'en_normalized.npy'\n",
    "    # model\n",
    "    model_directory = '../models/english/'\n",
    "    xgb_path = model_directory+'en_xgb_tuned-trained.pk'\n",
    "    dnc_path = model_directory+'dnc_translator/ckpt'\n",
    "    end_token = -1\n",
    "    # results\n",
    "    result_dir = '../results/english/'\n",
    "    result_csv = 'normalized.csv'\n",
    "\n",
    "elif lang == 'russian':\n",
    "    # input data\n",
    "    data_directory = '../data/russian/'\n",
    "    data = data_directory+'output-00099-of-00100_processed.csv'\n",
    "    vocab = data_directory+'ru_vocab.data'\n",
    "    # interim data\n",
    "    encoded_file = data_directory+'ru_encoded.npy'\n",
    "    encoded_len_file = data_directory+'ru_encoded_len.npy'\n",
    "    normalized_file = data_directory+'ru_normalized.npy'\n",
    "    # model\n",
    "    model_directory = '../models/russian/'\n",
    "    xgb_path = model_directory+'ru_xgb_tuned-trained.pk'\n",
    "    dnc_path = model_directory+'dnc_translator/ckpt'\n",
    "    end_token = -1\n",
    "    # results\n",
    "    result_dir = '../results/russian/'\n",
    "    result_csv = 'normalized.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load DNC Configurations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocab,'rb') as vf:        \n",
    "        vocab_load=pickle.loads(vf.read())\n",
    "start_token = vocab_load['output']['<GO>']\n",
    "input_vocab_len=len(vocab_load['input'])+1\n",
    "output_vocab_len=len(vocab_load['output'])+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Load Dataset\n",
    "<a id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Dataset by Sproat and Jaitly (2016) - An RNN Model of Text Normalization**  \n",
    "- English Source: https://storage.googleapis.com/text-normalization/en_with_types.tgz\n",
    "- Russian Source: https://storage.googleapis.com/text-normalization/ru_with_types.tgz  \n",
    "*The data is preprocessed for achieving results comparable to the ones presented in the above mentioned paper.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Read CSV as DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93196 entries, 0 to 93195\n",
      "Data columns (total 5 columns):\n",
      "sentence_id    93196 non-null int64\n",
      "token_id       93196 non-null int64\n",
      "semiotic       93196 non-null object\n",
      "before         93196 non-null object\n",
      "after          93196 non-null object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(data)\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>semiotic</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Сбор</td>\n",
       "      <td>Сбор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>село</td>\n",
       "      <td>село</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>в</td>\n",
       "      <td>в</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id semiotic before after\n",
       "0            0         0    PLAIN   Сбор  Сбор\n",
       "1            0         1    PUNCT      )     )\n",
       "2            0         2    PUNCT      —     —\n",
       "3            0         3    PLAIN   село  село\n",
       "4            0         4    PLAIN      в     в"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Dropping the ground truth labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data.drop(['after'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4. XGBoost Classification  \n",
    "<a id=\"xgb\"></a>\n",
    "**ToBeNormalized or RemainSame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# instantiate and load trained\n",
    "# XGBoost Model for classification\n",
    "xgb = XGB(xgb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100%        \r"
     ]
    }
   ],
   "source": [
    "# Class of tokens in the data\n",
    "raw_data['class'] = xgb.predict(data=raw_data)\n",
    "# Raw to Classified Data\n",
    "classified_data = raw_data.copy(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>semiotic</th>\n",
       "      <th>before</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89132</th>\n",
       "      <td>6508</td>\n",
       "      <td>15</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>отсутствует</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10130</th>\n",
       "      <td>754</td>\n",
       "      <td>6</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>театра</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58451</th>\n",
       "      <td>4256</td>\n",
       "      <td>12</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27642</th>\n",
       "      <td>1999</td>\n",
       "      <td>18</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Фильтровую</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40546</th>\n",
       "      <td>2950</td>\n",
       "      <td>21</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>методологий</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45070</th>\n",
       "      <td>3282</td>\n",
       "      <td>6</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>музыкант</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64527</th>\n",
       "      <td>4699</td>\n",
       "      <td>7</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>—</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91998</th>\n",
       "      <td>6722</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74773</th>\n",
       "      <td>5462</td>\n",
       "      <td>18</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>исторических</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34650</th>\n",
       "      <td>2526</td>\n",
       "      <td>9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>(</td>\n",
       "      <td>RemainSelf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id semiotic        before       class\n",
       "89132         6508        15    PLAIN   отсутствует  RemainSelf\n",
       "10130          754         6    PLAIN        театра  RemainSelf\n",
       "58451         4256        12    PUNCT             .  RemainSelf\n",
       "27642         1999        18    PLAIN    Фильтровую  RemainSelf\n",
       "40546         2950        21    PLAIN   методологий  RemainSelf\n",
       "45070         3282         6    PLAIN      музыкант  RemainSelf\n",
       "64527         4699         7    PUNCT             —  RemainSelf\n",
       "91998         6722         5    PUNCT             .  RemainSelf\n",
       "74773         5462        18    PLAIN  исторических  RemainSelf\n",
       "34650         2526         9    PUNCT             (  RemainSelf"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "id_tobenormalized = classified_data.index[classified_data['class']=='ToBeNormalized'].tolist()\n",
    "id_remainself = classified_data.index[classified_data['class']=='RemainSelf'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sanity Check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens to be normalized : 11312\n",
      "Tokens to remain self : 81884\n"
     ]
    }
   ],
   "source": [
    "print('Tokens to be normalized : {}'.format(len(id_tobenormalized)))\n",
    "print('Tokens to remain self : {}'.format(len(id_remainself)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 5. Encode Data\n",
    "<a id=\"encode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instatiate encoder with the vocabulary\n",
    "encoder = Encoder(vocab_file=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use existing Encoder Decoder parameters\n",
    "# to perform the decoding of the test data\n",
    "enc_data, enc_len = encoder.encode(classified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encode 'tobenormalized' tokens only\n",
    "tobenormalized_enc_data = enc_data[id_tobenormalized]\n",
    "tobenormalized_enc_len = enc_len[id_tobenormalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sanity check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens to be normalized : 11312\n"
     ]
    }
   ],
   "source": [
    "print('Tokens to be normalized : {}'.format(len(tobenormalized_enc_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Saving encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(encoded_file, tobenormalized_enc_data)\n",
    "np.save(encoded_len_file, tobenormalized_enc_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 6. DNC Normalization\n",
    "<a id=\"dnc\"></a>\n",
    "**Generate Normalized Form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tobenormalized_enc_data = np.load(encoded_file)\n",
    "tobenormalized_enc_len = np.load(encoded_len_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNCnormalize.config['num_encoder_symbols'] = input_vocab_len\n",
    "DNCnormalize.config['num_decoder_symbols'] = output_vocab_len \n",
    "DNCnormalize.config['start_token']= start_token\n",
    "DNCnormalize.config['end_token']= end_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DNC model at ../models/russian/dnc_translator/ckpt\n",
      "building model..\n",
      "building encoder..\n",
      "building decoder and attention..\n",
      "building greedy decoder..\n",
      "Reloading model parameters...\n",
      "INFO:tensorflow:Restoring parameters from ../models/russian/dnc_translator/ckpt\n",
      "model restored from ../models/russian/dnc_translator/ckpt\n",
      "Number of batches: 56\n",
      "Normalized 200 out of 11200\n"
     ]
    }
   ],
   "source": [
    "normalized_data = DNCnormalize.normalize(tobenormalized_enc_data, tobenormalized_enc_len,dnc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sanity Check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(tobenormalized_enc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Saving the normalized form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.save(normalized_file, normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 7. Data Postprocessing\n",
    "<a id=\"post\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Load Normalized Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normalized_data = np.load(normalized_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Encoded from to String form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting the numpy array to a list form\n",
    "normalized_data = normalized_data[0:tobenormalized_enc_len.shape[0]]\n",
    "normalized_data = np.split(normalized_data, normalized_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Total instances : {}'.format(len(normalized_data)))\n",
    "print('Shape of each instance : {}'.format(normalized_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reshaping the nested numpy arrays\n",
    "for i in range(len(normalized_data)):\n",
    "    normalized_data[i] = np.reshape(normalized_data[i],\n",
    "                                    normalized_data[i].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting encoded to string format\n",
    "str_converter = Normalized2String(vocab)\n",
    "for i in range(len(normalized_data)):\n",
    "    normalized_data[i]=str_converter.to_str(normalized_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A sneak peek..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normalized_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Merging Normalized with Remain Self**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_data['after'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_data.loc[id_tobenormalized, 'after'] = normalized_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RemainSelf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_data.loc[id_remainself, 'after'] = classified_data.loc[id_remainself, 'before'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A sneak peek into the final results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_data.loc[id_tobenormalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_data.to_csv(result_dir+result_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Analysis\n",
    "<a id=\"result\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(result_dir+result_csv)\n",
    "truth = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data.loc[truth['before']==truth['after'],'truth']='RemainSelf'\n",
    "classified_data.loc[truth['before']!=truth['after'],'truth']='ToBeNormalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data[classified_data['class']==classified_data['truth']].shape[0]/classified_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth['class']=''\n",
    "truth.loc[truth['before']!=truth['after'],'class']='ToBeNormalized'\n",
    "truth.loc[truth['before']==truth['after'],'class']='RemainSelf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_score = np.sum(truth['class']==results['class'])/truth.shape[0]\n",
    "print('Classification Accuracy on {} language is {:.5f}'.format(lang, classification_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(truth['semiotic']!=results['semiotic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(truth['after'].tolist(),\n",
    "                       results['after'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on {} language is {:.5f}'.format(lang, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semiotic class-wise accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_group = results.groupby('semiotic')\n",
    "truth_group = truth.groupby('semiotic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracy = pd.DataFrame(columns=['semiotic-class', 'accuracy', 'count', 'correct'])\n",
    "row = {'semiotic-class': 'ALL',\n",
    "       'accuracy': score,\n",
    "       'count': results.shape[0],\n",
    "       'correct': score*results.shape[0]}\n",
    "class_accuracy = class_accuracy.append(row, ignore_index=True)\n",
    "\n",
    "for results_items, truth_items in zip(results_group, truth_group):\n",
    "    semiotic_class = results_items[0]\n",
    "    results_items = results_items[1]\n",
    "    truth_items = truth_items[1]\n",
    "    score = accuracy_score(truth_items['after'].tolist(),\n",
    "                          results_items['after'].tolist())\n",
    "    row = {'semiotic-class': semiotic_class,\n",
    "           'accuracy': score,\n",
    "           'count': results_items.shape[0],\n",
    "           'correct': score*results_items.shape[0]}\n",
    "    class_accuracy = class_accuracy.append(row, ignore_index=True)\n",
    "class_accuracy['correct'] = class_accuracy['correct'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracy.plot(title='Semiotic Class-wise Accuracy',\n",
    "                    y=['count', 'correct'], x='semiotic-class',\n",
    "                    kind='bar', figsize=(20,10), grid=True)\n",
    "plt.savefig(result_dir+'Semiotic_Class-wise_Accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_accuracy.to_csv(result_dir+'classwise_accuracy.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization Mistakes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_mask = (results['after'] != truth['after'])\n",
    "mistakes = results[mistake_mask]\n",
    "mistakes = mistakes.assign(truth = truth.loc[mistake_mask, 'after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mistakes[mistakes['semiotic']=='TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class-wise mistakes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes_grouped = mistakes.groupby('semiotic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mistakes_grouped.apply(lambda x: x.sample(n=3, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes.to_csv(result_dir+'mistakes.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparison\n",
    "<a id=\"comparison\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv('../results/base-paper_classwise_accuracy.csv')\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_accuracy = pd.read_csv('../results/english/classwise_accuracy.csv')\n",
    "en_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_accuracy = pd.read_csv('../results/russian/classwise_accuracy.csv')\n",
    "ru_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_base = pd.DataFrame(columns=['semiotic-class', 'base accuracy', 'base count'])\n",
    "en_base['semiotic-class'] = base['Semiotic Class']\n",
    "en_base['base accuracy'] = base[' En Accuracy']\n",
    "en_base['base count'] = base[' En Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_base = pd.DataFrame(columns=['semiotic-class', 'base accuracy', 'base count'])\n",
    "ru_base['semiotic-class'] = base['Semiotic Class']\n",
    "ru_base['base accuracy'] = base[' Ru Accuracy']\n",
    "ru_base['base count'] = base[' Ru Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_compared = pd.merge(en_base, en_accuracy, on='semiotic-class')\n",
    "en_compared[['semiotic-class', 'accuracy', 'base accuracy', 'count', 'base count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_compared = pd.merge(ru_base, ru_accuracy, on='semiotic-class')\n",
    "ru_compared[['semiotic-class', 'accuracy', 'base accuracy', 'count', 'base count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latex Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(en_compared[['semiotic-class', 'base count','count','base accuracy','accuracy']].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ru_compared[['semiotic-class', 'base count','count','base accuracy','accuracy']].to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "<a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English Normalization Accuracy: 99.4% **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Russian Normalization Accuracy: 99.3% **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
